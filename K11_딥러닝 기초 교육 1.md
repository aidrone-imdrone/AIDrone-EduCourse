# ğŸ“Œ 1. ë”¥ëŸ¬ë‹ ê°œìš” (Introduction to Deep Learning)

## 1.1 ì¸ê³µì§€ëŠ¥(AI), ë¨¸ì‹ ëŸ¬ë‹(ML), ë”¥ëŸ¬ë‹(DL) ê°œë… ì°¨ì´

### ğŸ”¹ ì¸ê³µì§€ëŠ¥(AI, Artificial Intelligence)
ì¸ê³µì§€ëŠ¥(AI)ì€ **ì¸ê°„ì˜ ì‚¬ê³ ë°©ì‹ì„ ëª¨ë°©í•˜ëŠ” ì»´í“¨í„° ì‹œìŠ¤í…œ**ì„ ì˜ë¯¸í•©ë‹ˆë‹¤. AIëŠ” ì‚¬ëŒì´ ìˆ˜í–‰í•˜ëŠ” ì‘ì—…ì„ ìë™í™”í•˜ê³ , ì£¼ì–´ì§„ ë¬¸ì œë¥¼ í•´ê²°í•˜ë„ë¡ ì„¤ê³„ëœ ì•Œê³ ë¦¬ì¦˜ì„ í¬í•¨í•©ë‹ˆë‹¤.  
AIëŠ” í¬ê²Œ ë‘ ê°€ì§€ë¡œ ë‚˜ë‰©ë‹ˆë‹¤.

- **ì•½í•œ AI(Weak AI)**: íŠ¹ì • ì‘ì—…ì„ ìˆ˜í–‰í•˜ëŠ” AI (ì˜ˆ: ìŒì„± ë¹„ì„œ, ììœ¨ì£¼í–‰, ì´ë¯¸ì§€ ì¸ì‹)
- **ê°•í•œ AI(Strong AI)**: ì¸ê°„ì²˜ëŸ¼ ì‚¬ê³ í•˜ê³  ë¬¸ì œ í•´ê²°ì„ í•  ìˆ˜ ìˆëŠ” AI (ì•„ì§ ì—°êµ¬ ì¤‘)

### ğŸ”¹ ë¨¸ì‹ ëŸ¬ë‹(ML, Machine Learning)
ë¨¸ì‹ ëŸ¬ë‹ì€ **AIì˜ í•œ ë¶„ì•¼**ë¡œ, ë°ì´í„°ë¥¼ ì´ìš©í•˜ì—¬ **íŒ¨í„´ì„ í•™ìŠµ**í•˜ê³  ìŠ¤ìŠ¤ë¡œ **ê²°ì •ì„ ë‚´ë¦´ ìˆ˜ ìˆëŠ” ëª¨ë¸**ì„ ë§Œë“œëŠ” ê¸°ìˆ ì…ë‹ˆë‹¤.  
- ì „í†µì ì¸ í”„ë¡œê·¸ë˜ë°ê³¼ ë‹¬ë¦¬ **ê·œì¹™ì„ ì§ì ‘ ëª…ì‹œí•˜ì§€ ì•Šê³ **, ë°ì´í„°ë¥¼ í†µí•´ í•™ìŠµí•©ë‹ˆë‹¤.
- ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ì˜ ì¢…ë¥˜:
  - ì§€ë„ í•™ìŠµ (Supervised Learning): ë ˆì´ë¸”ì´ ìˆëŠ” ë°ì´í„°ë¥¼ í•™ìŠµ
  - ë¹„ì§€ë„ í•™ìŠµ (Unsupervised Learning): ë ˆì´ë¸” ì—†ì´ íŒ¨í„´ì„ ë°œê²¬
  - ê°•í™” í•™ìŠµ (Reinforcement Learning): ë³´ìƒì„ ê¸°ë°˜ìœ¼ë¡œ í•™ìŠµ

### ğŸ”¹ ë”¥ëŸ¬ë‹(DL, Deep Learning)
ë”¥ëŸ¬ë‹ì€ **ë¨¸ì‹ ëŸ¬ë‹ì˜ í•œ ë¶„ì•¼**ë¡œ, **ë‹¤ì¸µ ì‹ ê²½ë§(Deep Neural Networks, DNN)** ì„ ì´ìš©í•œ í•™ìŠµ ë°©ë²•ì…ë‹ˆë‹¤.  
- ì „í†µì ì¸ ë¨¸ì‹ ëŸ¬ë‹ì€ íŠ¹ì§•ì„ ì‚¬ëŒì´ ì§ì ‘ ì¶”ì¶œí•´ì•¼ í•˜ì§€ë§Œ, ë”¥ëŸ¬ë‹ì€ **ë°ì´í„°ì—ì„œ ìë™ìœ¼ë¡œ íŠ¹ì§•(feature)ì„ í•™ìŠµ**í•©ë‹ˆë‹¤.
- ë”¥ëŸ¬ë‹ì˜ í•µì‹¬ êµ¬ì¡°ëŠ” **ì¸ê³µ ì‹ ê²½ë§(ANN, Artificial Neural Networks)** ì´ë©°, ëŒ€í‘œì ì¸ ëª¨ë¸ì€ **CNN, RNN, Transformer** ë“±ì´ ìˆìŠµë‹ˆë‹¤.

---

## 1.2 ë”¥ëŸ¬ë‹ì˜ ì—­ì‚¬ ë° ë°œì „ ê³¼ì •

ë”¥ëŸ¬ë‹ì˜ ë°œì „ ê³¼ì •ì€ ë‹¤ìŒê³¼ ê°™ì´ ìš”ì•½í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

| ì—°ë„ | ì£¼ìš” ë°œì „ ì‚¬í•­ |
|------|--------------|
| 1943 | ì›Œë Œ ë§¥ì»¬ëŸ­ê³¼ ì›”í„° í”¼ì¸ (Warren McCulloch & Walter Pitts)ê°€ ìµœì´ˆì˜ ì‹ ê²½ë§ ê°œë… ì œì•ˆ |
| 1957 | í”„ë­í¬ ë¡œì  ë¸”ë«(Frank Rosenblatt)ì´ í¼ì…‰íŠ¸ë¡ (Perceptron) ëª¨ë¸ ë°œí‘œ |
| 1980s | ë°±í”„ë¡œíŒŒê²Œì´ì…˜(Backpropagation) ì•Œê³ ë¦¬ì¦˜ ë“±ì¥ (Geoffrey Hinton) |
| 1990s | CNN(Convolutional Neural Network) ê°œë°œ (LeNet-5 by Yann LeCun) |
| 2006 | ë”¥ëŸ¬ë‹ì´ ì£¼ëª©ë°›ê¸° ì‹œì‘ (Geoffrey Hintonì˜ ì‹¬ì¸µ ì‹ ê²½ë§ ì—°êµ¬) |
| 2012 | AlexNet(ì´ë¯¸ì§€ ë¶„ë¥˜ ëª¨ë¸)ì´ ImageNet ëŒ€íšŒì—ì„œ ì••ë„ì ì¸ ì„±ëŠ¥ì„ ë³´ì´ë©° ë”¥ëŸ¬ë‹ì´ ê¸‰ë¶€ìƒ |
| 2014 | GAN(Generative Adversarial Networks) ë“±ì¥ |
| 2017 | íŠ¸ëœìŠ¤í¬ë¨¸(Transformer) ëª¨ë¸ ë“±ì¥ (êµ¬ê¸€) |
| 2020s | GPT, DALL-E, Stable Diffusion ê°™ì€ ëŒ€í˜• ëª¨ë¸ì´ í™œë°œíˆ ì—°êµ¬ë¨ |

---

## 1.3 ë”¥ëŸ¬ë‹ì´ í™œìš©ë˜ëŠ” ë¶„ì•¼

ë”¥ëŸ¬ë‹ì€ ë‹¤ì–‘í•œ ë¶„ì•¼ì—ì„œ í™œìš©ë˜ê³  ìˆìœ¼ë©°, ëŒ€í‘œì ì¸ ì‘ìš© ì‚¬ë¡€ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.

### âœ… ì»´í“¨í„° ë¹„ì „ (Computer Vision)
- ì´ë¯¸ì§€ ë¶„ë¥˜ (Image Classification): ì˜ˆ) ì‚¬ëŒ ì–¼êµ´ ì¸ì‹, ì˜ë£Œ ì˜ìƒ ë¶„ì„
- ê°ì²´ ê²€ì¶œ (Object Detection): ì˜ˆ) CCTV ë³´ì•ˆ, ììœ¨ì£¼í–‰
- ìŠ¤íƒ€ì¼ ë³€í™˜ (Style Transfer): ì˜ˆ) í™”ê°€ì˜ ê·¸ë¦¼ ìŠ¤íƒ€ì¼ì„ ì´ë¯¸ì§€ì— ì ìš©

### âœ… ìì—°ì–´ ì²˜ë¦¬ (NLP, Natural Language Processing)
- ê¸°ê³„ ë²ˆì—­ (Machine Translation): ì˜ˆ) Google Translate
- ê°ì • ë¶„ì„ (Sentiment Analysis): ì˜ˆ) ë¦¬ë·°ì—ì„œ ê¸ì •/ë¶€ì • íŒë‹¨
- í…ìŠ¤íŠ¸ ìƒì„± (Text Generation): ì˜ˆ) ChatGPT, BERT ê¸°ë°˜ ëª¨ë¸

### âœ… ììœ¨ì£¼í–‰ (Autonomous Driving)
- ì°¨ì„  ê°ì§€, ë³´í–‰ì ì¸ì‹, ì‹ í˜¸ë“± íŒë³„ ë“±ì˜ ê¸°ìˆ 
- í…ŒìŠ¬ë¼(Tesla), ì›¨ì´ëª¨(Waymo) ê°™ì€ ê¸°ì—…ì´ ì—°êµ¬ ì¤‘

### âœ… ì¶”ì²œ ì‹œìŠ¤í…œ (Recommendation Systems)
- ë„·í”Œë¦­ìŠ¤, ìœ íŠœë¸Œ, ì•„ë§ˆì¡´ì˜ ì½˜í…ì¸  ì¶”ì²œ

ì´ ì™¸ì—ë„ **ì˜ë£Œ ì§„ë‹¨, ê¸ˆìœµ ì˜ˆì¸¡, ë“œë¡  ì œì–´, ë¡œë´‡ ì œì–´** ë“±ì˜ ë‹¤ì–‘í•œ ë¶„ì•¼ì—ì„œ ë”¥ëŸ¬ë‹ì´ í™œìš©ë©ë‹ˆë‹¤.

---

## 1.4 ì™œ ë”¥ëŸ¬ë‹ì´ ì¤‘ìš”í•œê°€?

ë”¥ëŸ¬ë‹ì´ ìµœê·¼ ê¸‰ê²©íˆ ë°œì „í•œ ì´ìœ ëŠ” **ë°ì´í„°, ì—°ì‚°ë ¥, ì•Œê³ ë¦¬ì¦˜ì˜ ë°œì „** ë•ë¶„ì…ë‹ˆë‹¤.

### ğŸ“Œ 1ï¸âƒ£ ë°ì´í„°(Big Data)ì˜ ì¦ê°€
- ìŠ¤ë§ˆíŠ¸í°, ì¸í„°ë„·, IoT ê¸°ê¸°ì˜ ë°œì „ìœ¼ë¡œ ì—„ì²­ë‚œ ì–‘ì˜ ë°ì´í„°ê°€ ìƒì„±ë¨
- ë”¥ëŸ¬ë‹ ëª¨ë¸ì´ í•™ìŠµí•  ìˆ˜ ìˆëŠ” ì¶©ë¶„í•œ ë°ì´í„°ê°€ í™•ë³´ë¨

### ğŸ“Œ 2ï¸âƒ£ ì—°ì‚°ë ¥(Computational Power)ì˜ í–¥ìƒ
- GPU(ê·¸ë˜í”½ í”„ë¡œì„¸ì„œ)ì˜ ë°œì „ìœ¼ë¡œ ë³‘ë ¬ ì—°ì‚° ê°€ëŠ¥
- TPU(Tensor Processing Unit) ê°™ì€ ë”¥ëŸ¬ë‹ ì „ìš© í•˜ë“œì›¨ì–´ ë“±ì¥

### ğŸ“Œ 3ï¸âƒ£ ì•Œê³ ë¦¬ì¦˜ì˜ ê°œì„ 
- CNN, RNN, Transformer ê°™ì€ íš¨ìœ¨ì ì¸ êµ¬ì¡° ë“±ì¥
- ìµœì í™” ì•Œê³ ë¦¬ì¦˜(Adam, RMSprop ë“±)ì˜ ë°œì „ìœ¼ë¡œ í•™ìŠµ ì†ë„ ì¦ê°€

---

## ğŸ›  ì‹¤ìŠµ: ê°„ë‹¨í•œ í¼ì…‰íŠ¸ë¡  ëª¨ë¸ ì§ì ‘ êµ¬í˜„ (NumPy ì‚¬ìš©)

í¼ì…‰íŠ¸ë¡ (Perceptron)ì€ ê°€ì¥ ê¸°ë³¸ì ì¸ ì‹ ê²½ë§ ëª¨ë¸ì…ë‹ˆë‹¤.  
ì•„ë˜ ì½”ë“œë¥¼ ì‹¤í–‰í•˜ì—¬ í¼ì…‰íŠ¸ë¡ ì´ ì–´ë–»ê²Œ ì‘ë™í•˜ëŠ”ì§€ ì‹¤ìŠµí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### ğŸ”¹ í¼ì…‰íŠ¸ë¡  êµ¬í˜„ (AND ê²Œì´íŠ¸ í•™ìŠµ)

```python
import numpy as np

# AND ê²Œì´íŠ¸ ë°ì´í„°ì…‹
X = np.array([[0,0], [0,1], [1,0], [1,1]])  # ì…ë ¥
y = np.array([0, 0, 0, 1])  # ì •ë‹µ

# ê°€ì¤‘ì¹˜ ì´ˆê¸°í™”
w = np.random.rand(2)
b = np.random.rand(1)
learning_rate = 0.1

# í¼ì…‰íŠ¸ë¡  í•™ìŠµ
for epoch in range(10):  # 10ë²ˆ ë°˜ë³µ
    for i in range(len(X)):
        z = np.dot(X[i], w) + b  # ê°€ì¤‘ì¹˜ ê³± + í¸í–¥
        y_pred = 1 if z > 0 else 0  # í™œì„±í™” í•¨ìˆ˜
        error = y[i] - y_pred
        w += learning_rate * error * X[i]  # ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸
        b += learning_rate * error  # í¸í–¥ ì—…ë°ì´íŠ¸

print("í•™ìŠµ ì™„ë£Œëœ ê°€ì¤‘ì¹˜:", w)
print("í•™ìŠµ ì™„ë£Œëœ í¸í–¥:", b)

