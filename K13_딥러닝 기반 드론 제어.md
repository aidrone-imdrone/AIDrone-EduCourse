
# 미니 드론용 시각적 장애물 감지 및 회피 시스템

이 프로젝트는 라즈베리파이 Zero 2W 기반 미니 드론(8520 DC 모터 사용)을 위한 경량 장애물 감지 및 회피 시스템을 구현합니다. 시스템은 컴퓨터 비전과 딥러닝을 사용하여 실시간으로 장애물을 감지하고 회피 경로를 설정합니다.

![장애물 감지 데모](https://github.com/user-attachments/assets/placeholder-image.jpg)

## 기능

- MobileNet SSD Lite를 사용한 실시간 장애물 감지
- 라즈베리파이 Zero 2W에 최적화된 경량 구현
- 방향 결정이 포함된 간단한 회피 알고리즘
- 반응성 높은 비행 제어를 위한 저지연 처리
- 다양한 장애물 클래스 지원(사람, 가구, 벽 등)

## 하드웨어 요구사항

- 라즈베리파이 Zero 2W
- 라즈베리파이 카메라 모듈(v2 권장)
- 8520 DC 모터가 장착된 미니 드론 프레임
- 라즈베리파이와 호환되는 비행 컨트롤러
- 3.7V LiPo 배터리
- 라즈베리파이 장착용 경량 섀시

## 소프트웨어 요구사항

- 라즈베리파이 OS(Lite 버전 권장)
- Python 3.7 이상
- TensorFlow Lite
- OpenCV
- RPi.GPIO 또는 적절한 모터 제어 라이브러리

## 설치 방법

```bash
# 시스템 패키지 업데이트
sudo apt update
sudo apt upgrade -y

# 의존성 설치
sudo apt install -y python3-pip python3-opencv libjpeg-dev libopenjp2-7-dev

# Python 패키지 설치
pip3 install RPi.GPIO numpy tflite-runtime opencv-python-headless picamera2

# 저장소 복제
git clone https://github.com/yourusername/drone-obstacle-detection.git
cd drone-obstacle-detection

# 사전 훈련된 모델 다운로드
./download_model.sh
```

## 작동 원리

### 1. 객체 감지

시스템은 라즈베리파이 Zero 2W에서의 추론 속도를 향상시키기 위해 최적화된 사전 훈련된 MobileNet SSD 모델을 사용합니다. 모델은 TensorFlow Lite 형식으로 양자화되어 성능이 개선되었습니다.

### 2. 장애물 분석

장애물이 감지되면, 시스템은 장애물의 위치, 크기, 클래스를 분석하여 위험 수준을 결정합니다. 드론 경로에 직접 위치한 물체에 가장 높은 우선순위가 부여됩니다.

### 3. 회피 전략

시스템은 간단하면서도 효과적인 회피 전략을 구현합니다:
- 왼쪽에 장애물이 감지되면 오른쪽으로 이동
- 오른쪽에 장애물이 감지되면 왼쪽으로 이동
- 직접 앞에 장애물이 감지되면 제자리에서 호버링한 후 가능하면 위로 이동
- 여러 장애물이 감지되면 최대 여유 공간이 있는 경로 선택

### 4. 제어 통합

회피 전략에 따라 드론의 궤적을 조정하기 위한 명령이 비행 컨트롤러로 전송됩니다.

## 사용 방법

```bash
# 기본 사용법
python3 obstacle_avoidance.py

# 시각화 사용 (HDMI 연결 또는 VNC 필요)
python3 obstacle_avoidance.py --visualize

# 감지 신뢰도 임계값 조정
python3 obstacle_avoidance.py --threshold 0.5

# 모터 제어 없이 테스트
python3 obstacle_avoidance.py --simulation
```

## 코드 구조

- `obstacle_avoidance.py`: 장애물 감지 및 회피 시스템의 메인 스크립트
- `drone_control.py`: 드론 모터 제어를 위한 함수
- `detection_utils.py`: 객체 감지 및 처리를 위한 유틸리티 함수
- `models/`: TensorFlow Lite 모델과 라벨이 포함된 디렉토리

## 구현 예제

다음은 핵심 장애물 감지 및 회피 시스템의 간단한 구현입니다:

```python
import time
import numpy as np
import cv2
from picamera2 import Picamera2
import tflite_runtime.interpreter as tflite
from drone_control import DroneController

class ObstacleAvoidanceSystem:
    def __init__(self, model_path="models/detect.tflite", 
                 label_path="models/labelmap.txt", 
                 threshold=0.5,
                 visualize=False):
        # 카메라 초기화
        self.camera = Picamera2()
        config = self.camera.create_preview_configuration(main={"size": (640, 480)})
        self.camera.configure(config)
        self.camera.start()
        time.sleep(1)  # 카메라 초기화 시간 부여
        
        # TFLite 모델 로드
        self.interpreter = tflite.Interpreter(model_path=model_path)
        self.interpreter.allocate_tensors()
        
        # 모델 세부 정보 가져오기
        self.input_details = self.interpreter.get_input_details()
        self.output_details = self.interpreter.get_output_details()
        self.height = self.input_details[0]['shape'][1]
        self.width = self.input_details[0]['shape'][2]
        
        # 라벨 로드
        with open(label_path, 'r') as f:
            self.labels = [line.strip() for line in f.readlines()]
            
        # 드론 컨트롤러 초기화
        self.drone = DroneController()
        
        # 감지 임계값 설정
        self.threshold = threshold
        self.visualize = visualize
        
        print("장애물 회피 시스템 초기화 완료")
        
    def preprocess_image(self, image):
        # 크기 조정 및 RGB로 변환
        input_image = cv2.resize(image, (self.width, self.height))
        input_image = cv2.cvtColor(input_image, cv2.COLOR_BGR2RGB)
        
        # 정규화 및 배치 차원 추가
        input_image = input_image.astype(np.float32) / 127.5 - 1
        input_image = np.expand_dims(input_image, axis=0)
        
        return input_image
        
    def detect_obstacles(self, image):
        # 이미지 전처리
        input_data = self.preprocess_image(image)
        
        # 입력 텐서 설정
        self.interpreter.set_tensor(self.input_details[0]['index'], input_data)
        
        # 추론 실행
        self.interpreter.invoke()
        
        # 결과 가져오기
        boxes = self.interpreter.get_tensor(self.output_details[0]['index'])[0]
        classes = self.interpreter.get_tensor(self.output_details[1]['index'])[0]
        scores = self.interpreter.get_tensor(self.output_details[2]['index'])[0]
        
        # 임계값 기반 감지 필터링
        valid_detections = scores > self.threshold
        
        return boxes[valid_detections], classes[valid_detections], scores[valid_detections]
    
    def calculate_avoidance_direction(self, image, boxes):
        h, w, _ = image.shape
        center_x = w // 2
        
        # 장애물이 위치한 지역 분석
        left_zone_obstacles = 0
        right_zone_obstacles = 0
        center_zone_obstacles = 0
        
        for box in boxes:
            y_min, x_min, y_max, x_max = box
            
            # 정규화된 좌표를 픽셀 값으로 변환
            x_min = int(x_min * w)
            x_max = int(x_max * w)
            
            # 장애물 중심 계산
            obj_center_x = (x_min + x_max) // 2
            
            # 장애물이 어느 영역에 있는지 결정
            if obj_center_x < center_x - w//6:  # 왼쪽 영역
                left_zone_obstacles += 1
            elif obj_center_x > center_x + w//6:  # 오른쪽 영역
                right_zone_obstacles += 1
            else:  # 중앙 영역
                center_zone_obstacles += 1
        
        # 회피 방향 결정
        if center_zone_obstacles > 0:
            # 직접 앞에 장애물이 있으면 장애물이 적은 쪽으로 이동하거나 위로 이동
            if left_zone_obstacles <= right_zone_obstacles:
                return "LEFT"
            else:
                return "RIGHT"
        elif left_zone_obstacles > right_zone_obstacles:
            return "RIGHT"
        elif right_zone_obstacles > left_zone_obstacles:
            return "LEFT"
        else:
            return "FORWARD"
    
    def apply_avoidance_control(self, direction):
        if direction == "LEFT":
            print("오른쪽에 장애물 감지 - 왼쪽으로 이동")
            self.drone.move_left()
        elif direction == "RIGHT":
            print("왼쪽에 장애물 감지 - 오른쪽으로 이동")
            self.drone.move_right()
        elif direction == "UP":
            print("전방에 장애물 감지 - 위로 이동")
            self.drone.move_up()
        else:
            print("경로 확보 - 전진")
            self.drone.move_forward()
    
    def visualize_detection(self, image, boxes, classes, scores):
        h, w, _ = image.shape
        for i in range(len(boxes)):
            # 박스 좌표 가져오기
            y_min, x_min, y_max, x_max = boxes[i]
            
            # 정규화된 좌표를 픽셀 값으로 변환
            x_min = int(x_min * w)
            x_max = int(x_max * w)
            y_min = int(y_min * h)
            y_max = int(y_max * h)
            
            # 감지된 객체 주변에 사각형 그리기
            cv2.rectangle(image, (x_min, y_min), (x_max, y_max), (0, 255, 0), 2)
            
            # 라벨 추가
            class_id = int(classes[i])
            label = f"{self.labels[class_id]}: {scores[i]:.2f}"
            cv2.putText(image, label, (x_min, y_min - 10),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)
        
        return image
    
    def run(self):
        try:
            while True:
                # 프레임 캡처
                image = self.camera.capture_array()
                
                # 장애물 감지
                boxes, classes, scores = self.detect_obstacles(image)
                
                if len(boxes) > 0:
                    # 회피 방향 계산
                    direction = self.calculate_avoidance_direction(image, boxes)
                    
                    # 회피 제어 적용
                    self.apply_avoidance_control(direction)
                    
                    # 시각화 활성화 시 표시
                    if self.visualize:
                        image = self.visualize_detection(image, boxes, classes, scores)
                        cv2.imshow("장애물 감지", image)
                        if cv2.waitKey(1) & 0xFF == ord('q'):
                            break
                else:
                    # 장애물 없음, 전진 계속
                    self.drone.move_forward()
                
                # 프레임 속도 제어를 위한 sleep
                time.sleep(0.1)
                
        except KeyboardInterrupt:
            print("장애물 회피 시스템 중지")
        
        finally:
            # 정리
            self.camera.stop()
            if self.visualize:
                cv2.destroyAllWindows()
            self.drone.stop()

if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description='드론 장애물 회피 시스템')
    parser.add_argument('--threshold', type=float, default=0.5,
                        help='감지 신뢰도 임계값')
    parser.add_argument('--visualize', action='store_true',
                        help='시각화 활성화')
    parser.add_argument('--simulation', action='store_true',
                        help='시뮬레이션 모드로 실행(모터 제어 없음)')
    
    args = parser.parse_args()
    
    # 시스템 생성 및 실행
    obstacle_system = ObstacleAvoidanceSystem(
        threshold=args.threshold,
        visualize=args.visualize
    )
    
    obstacle_system.run()
```

## 드론 제어 모듈 예제

다음은 드론 제어 모듈의 간단한 예제입니다:

```python
import time
import RPi.GPIO as GPIO

class DroneController:
    def __init__(self):
        # 모터 제어를 위한 GPIO 설정
        GPIO.setmode(GPIO.BCM)
        
        # 모터용 GPIO 핀 정의
        self.MOTOR_PINS = {
            'front_left': {'pin': 17, 'direction': 18},
            'front_right': {'pin': 22, 'direction': 23},
            'back_left': {'pin': 24, 'direction': 25},
            'back_right': {'pin': 27, 'direction': 26}
        }
        
        # GPIO 핀 설정
        for motor in self.MOTOR_PINS.values():
            GPIO.setup(motor['pin'], GPIO.OUT)
            GPIO.setup(motor['direction'], GPIO.OUT)
            
            # 속도 제어를 위한 PWM 초기화
            motor['pwm'] = GPIO.PWM(motor['pin'], 100)
            motor['pwm'].start(0)
        
        print("드론 컨트롤러 초기화 완료")
    
    def _set_motor_speed(self, motor_name, speed, direction):
        """특정 모터의 속도와 방향 설정"""
        motor = self.MOTOR_PINS[motor_name]
        GPIO.output(motor['direction'], direction)
        motor['pwm'].ChangeDutyCycle(speed)
    
    def move_forward(self):
        """드론 전진"""
        print("전진 중")
        self._set_motor_speed('front_left', 70, 1)
        self._set_motor_speed('front_right', 70, 1)
        self._set_motor_speed('back_left', 70, 1)
        self._set_motor_speed('back_right', 70, 1)
    
    def move_left(self):
        """드론 왼쪽 이동"""
        print("왼쪽으로 이동 중")
        self._set_motor_speed('front_left', 40, 1)
        self._set_motor_speed('front_right', 70, 1)
        self._set_motor_speed('back_left', 40, 1)
        self._set_motor_speed('back_right', 70, 1)
    
    def move_right(self):
        """드론 오른쪽 이동"""
        print("오른쪽으로 이동 중")
        self._set_motor_speed('front_left', 70, 1)
        self._set_motor_speed('front_right', 40, 1)
        self._set_motor_speed('back_left', 70, 1)
        self._set_motor_speed('back_right', 40, 1)
    
    def move_up(self):
        """드론 위로 이동"""
        print("위로 이동 중")
        self._set_motor_speed('front_left', 90, 1)
        self._set_motor_speed('front_right', 90, 1)
        self._set_motor_speed('back_left', 90, 1)
        self._set_motor_speed('back_right', 90, 1)
    
    def hover(self):
        """제자리 호버링"""
        print("호버링 중")
        self._set_motor_speed('front_left', 60, 1)
        self._set_motor_speed('front_right', 60, 1)
        self._set_motor_speed('back_left', 60, 1)
        self._set_motor_speed('back_right', 60, 1)
    
    def stop(self):
        """모든 모터 정지"""
        print("모터 정지 중")
        self._set_motor_speed('front_left', 0, 0)
        self._set_motor_speed('front_right', 0, 0)
        self._set_motor_speed('back_left', 0, 0)
        self._set_motor_speed('back_right', 0, 0)
        
        # GPIO 정리
        GPIO.cleanup()
```

## 모델 다운로드 스크립트

다음은 사전 훈련된 모델을 다운로드하는 유틸리티 스크립트입니다:

```bash
#!/bin/bash

MODEL_DIR="models"
mkdir -p $MODEL_DIR

echo "TFLite 모델 다운로드 중..."
wget -O $MODEL_DIR/detect.tflite https://storage.googleapis.com/download.tensorflow.org/models/tflite/coco_ssd_mobilenet_v1_1.0_quant_2018_06_29.zip
unzip -j $MODEL_DIR/detect.tflite -d $MODEL_DIR
rm $MODEL_DIR/detect.tflite

echo "라벨 맵 다운로드 중..."
wget -O $MODEL_DIR/labelmap.txt https://raw.githubusercontent.com/tensorflow/tensorflow/master/tensorflow/lite/examples/object_detection/android/app/src/main/assets/labelmap.txt

echo "다운로드 완료!"
```

## 성능 최적화

연산 자원이 제한된 라즈베리파이 Zero 2W를 위해 몇 가지 최적화가 구현되었습니다:

1. **모델 양자화**: 메모리 및 연산 요구사항을 줄이기 위해 8비트 양자화 모델 사용
2. **해상도 감소**: 연산 부하를 줄이기 위해 320x240 또는 더 작은 프레임 처리
3. **프레임 스킵**: 실시간 성능을 유지하기 위해 모든 프레임이 아닌 일부 프레임만 처리
4. **ROI 처리**: 전체 프레임이 아닌 관심 영역만 분석
5. **단순화된 결정 로직**: 복잡한 경로 계획 대신 효율적인 결정 알고리즘 사용

## 보정 및 테스트

드론에 시스템을 배포하기 전에:

1. 드론이 정지 상태일 때 카메라와 함께 객체 감지 모델 테스트
2. 다양한 명령에 대한 모터 반응 보정
3. 부드러운 장애물이 있는 통제된 환경에서 시스템 테스트
4. 신뢰성이 확인되면 비행 복잡성을 점진적으로 증가

## 문제 해결

- **높은 지연 시간**: 이미지 해상도를 줄이거나 프레임 스킵 증가
- **오탐지**: 신뢰도 임계값을 높이거나 특정 클래스 필터링
- **불규칙한 움직임**: 모터 제어 매개변수 및 스무딩 알고리즘 조정
- **배터리 소모**: 처리 빈도 감소 또는 모델 추가 최적화
- **카메라 문제**: 카메라 연결 상태와 충분한 조명 확인

## 향후 개선 사항

- 스테레오 비전 또는 IR 센서를 사용한 깊이 추정 구현
- 회피 방향 사이의 진동을 방지하기 위한 경로 메모리 추가
- 더 정교한 경로 계획 알고리즘 구현
- 시간이 지남에 따라 회피 전략을 개선하는 학습 기능 추가
- 실외 내비게이션 시나리오를 위한 GPS 통합

## 라이선스

이 프로젝트는 MIT 라이선스 하에 제공됩니다 - 자세한 내용은 LICENSE 파일을 참조하세요.

## 감사의 말

- 사전 훈련된 모델을 제공한 TensorFlow Lite 팀
- 라즈베리파이 재단
- 영감과 코드 참조를 제공한 오픈소스 드론 커뮤니티
